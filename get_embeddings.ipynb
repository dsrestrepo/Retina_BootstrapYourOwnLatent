{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a9c5e7",
   "metadata": {},
   "source": [
    "### Setup Environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c2d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.embeddings import get_embeddings_df\n",
    "from src.model import FoundationalCVModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189dfa95",
   "metadata": {},
   "source": [
    "## Embeddings Generation\n",
    "\n",
    "* **Batch Size:** Images per batch to convert to embeddings (Adjust depending on your memory)\n",
    "\n",
    "* **Path:** Path to the images\n",
    "\n",
    "* **Output Directory:** Directory to save the embeddings\n",
    "\n",
    "* **Backbone:** Select a backbone from the list of possible backbones:\n",
    "    * 'dinov2_small'\n",
    "    * 'dinov2_base'\n",
    "    * 'dinov2_large'\n",
    "    * 'dinov2_giant'\n",
    "    * 'clip_base',\n",
    "    * 'clip_large',\n",
    "    * 'convnextv2_tiny'\n",
    "    * 'convnextv2_base'\n",
    "    * 'convnextv2_large'\n",
    "    * 'convnext_tiny'\n",
    "    * 'convnext_small'\n",
    "    * 'convnext_base'\n",
    "    * 'convnext_large'\n",
    "    * 'swin_tiny'\n",
    "    * 'swin_small'\n",
    "    * 'swin_base'\n",
    "    * 'vit_base'\n",
    "    * 'vit_large'\n",
    "    * 'retfound'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1fabda",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d21b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "path = '/home/opc/Retina/BRSET/images/'\n",
    "out_dir = 'Embeddings'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d98bbf",
   "metadata": {},
   "source": [
    "### Get RetFound embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1286428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see cuda devices available\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a25d85f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################  Generating Embeddings  ##################################################\n",
      "Processed batch number: 10\n",
      "Processed batch number: 20\n",
      "Processed batch number: 30\n",
      "Processed batch number: 40\n",
      "Processed batch number: 50\n",
      "Processed batch number: 60\n",
      "Processed batch number: 70\n",
      "Processed batch number: 80\n",
      "Processed batch number: 90\n",
      "Processed batch number: 100\n",
      "Processed batch number: 110\n",
      "Processed batch number: 120\n",
      "Processed batch number: 130\n",
      "Processed batch number: 140\n",
      "Processed batch number: 150\n",
      "Processed batch number: 160\n",
      "Processed batch number: 170\n",
      "Processed batch number: 180\n",
      "Processed batch number: 190\n",
      "Processed batch number: 200\n",
      "Processed batch number: 210\n",
      "Processed batch number: 220\n",
      "Processed batch number: 230\n",
      "Processed batch number: 240\n",
      "Processed batch number: 250\n",
      "Processed batch number: 260\n",
      "Processed batch number: 270\n",
      "Processed batch number: 280\n",
      "Processed batch number: 290\n",
      "Processed batch number: 300\n",
      "Processed batch number: 310\n",
      "Processed batch number: 320\n",
      "Processed batch number: 330\n",
      "Processed batch number: 340\n",
      "Processed batch number: 350\n",
      "Processed batch number: 360\n",
      "Processed batch number: 370\n",
      "Processed batch number: 380\n",
      "Processed batch number: 390\n",
      "Processed batch number: 400\n",
      "Processed batch number: 410\n",
      "Processed batch number: 420\n",
      "Processed batch number: 430\n",
      "Processed batch number: 440\n",
      "Processed batch number: 450\n",
      "Processed batch number: 460\n",
      "Processed batch number: 470\n",
      "Processed batch number: 480\n",
      "Processed batch number: 490\n",
      "Processed batch number: 500\n"
     ]
    }
   ],
   "source": [
    "BACKBONE = 'convnextv2_base'\n",
    "MODE = 'eval'\n",
    "# Create the model\n",
    "backbone = FoundationalCVModel(backbone=BACKBONE, mode=MODE)\n",
    "# Load backbone weights:\n",
    "backbone.load_state_dict(torch.load('Models/checkpoint_convnextv2_base_byol.pt'))\n",
    "\n",
    "get_embeddings_df(batch_size=batch_size, path=path, backbone=backbone, directory=out_dir, weights=None, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
